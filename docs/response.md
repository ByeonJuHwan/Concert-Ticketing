# 장애대응

콘서트 좌석 예약의 경우 부하테스트 결과 6,000명 이상의 부하가 몰릴시 장애로 이어집니다.

따라서 6,000명 이상의 부하가 발생했을시 어떻게 해결하고 대응해야하는지 가상 장애 대응을 진행해 보겠습니다.

## 장애 모니터링 및 알림

콘서트 좌석 예약 시스템에는 Grafana 를 사용하여 시스템을 지속적으로 모니터링을 진행하며, 이 모니터링 시스템에서 이상 현상을 탐지하면,
즉각적으로 인지하기 위해서 Slack 으로 알림을 발송하도록 처리했습니다.

![](https://velog.velcdn.com/images/asdcz11/post/585bd365-c4b6-4fb2-a15b-b2b65e749f35/image.png)

대기열 이라는 특성상 급격하게 부하가 몰릴수 있기 때문에 CPU 사용량이 급격히 증가합니다.
따라서 시스템의 CPU 허용량을 넘어서 장애로 발생되기 전에 사용량 80 % 가 된다면 담당자가 인지하고 대응할수 있도록 했습니다.

## 원인 분석 및 조치

- 데이터베이스 연결 풀이 포화 상태임을 확인
- 애플리케이션 서버의 스레드 풀도 거의 소진된 상태 확인

1. 데이터베이스 연결 풀 확장
    - 최대 연결수를 200 -> 400으로 증가
    - HikariCP 설정 조정
2. 애플리케이션 서버 스케일 아웃
   - Kubernetes 클러스터에 3개의 새로운 파드 추가
3. 캐시 레이어 강화
    - Redis 캐시 크기 2배 확장
    - 자주 조회되는 콘서트 정보 캐시 적용

## 안정화 및 모니터링

CPU 사용량이 정상적으로 돌아올 경우 Grafana 에서 감지하고 정상적으로 돌아왔다고 알림을 보내줍니다.

![](https://velog.velcdn.com/images/asdcz11/post/9459a990-ccb1-4ada-a948-d57e6d72ba17/image.png)

## 사후 분석 및 개선계획

1. 자동 스케일링 정책 수립
2. 데이터베이스 쿼리 최적화
3. 부하 테스트 시나리오 강화
4. 긴급 상황 대응 메뉴얼 업데이트

